{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pihchikk/machine-learning-to-predict-the-oxidizaility-of-organic-carbon-in-surface-soil/blob/main/data%20preprocessing/notebooks/Tambov_phenology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHnRamyBW9ho"
      },
      "source": [
        "### Auth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-shrgnn')"
      ],
      "metadata": {
        "id": "mqlHhvUhtzXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0qwsrHbW1K7"
      },
      "source": [
        "### ROI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz-HUysxW1Uv"
      },
      "outputs": [],
      "source": [
        "from pyproj import Proj, transform\n",
        "\n",
        "# Define the EPSG code for EPSG:32637 (UTM Zone 37N) and WGS84\n",
        "epsg_32637 = Proj(init='epsg:32637')\n",
        "wgs84 = Proj(init='epsg:4326')\n",
        "\n",
        "# Coordinates in EPSG:32637\n",
        "x1, y1 = 647500, 5766000\n",
        "x2, y2 = 651000, 5770000\n",
        "\n",
        "# Convert EPSG:32637 coordinates to WGS84\n",
        "lon1, lat1 = transform(epsg_32637, wgs84, x1, y1)\n",
        "lon2, lat2 = transform(epsg_32637, wgs84, x2, y2)\n",
        "\n",
        "region = ee.Geometry.Polygon(\n",
        "  [[[lon1, lat2],\n",
        "    [lon1, lat1],\n",
        "    [lon2, lat1],\n",
        "    [lon2, lat2]]], None, False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_J_iyhrP4vF"
      },
      "source": [
        "### Date ranges (half-month averaging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvLn5ktZWowF"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Define the list of months\n",
        "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12'][2:12]\n",
        "\n",
        "# Function to get the maximum day of the month\n",
        "def max_day(month):\n",
        "    if month in ['01', '03', '05', '07', '08', '10', '12']:\n",
        "        return '31'\n",
        "    elif month == '02':\n",
        "        return '28'  # Assuming non-leap year for simplicity\n",
        "    else:\n",
        "        return '30'\n",
        "\n",
        "# Create the list comprehension for first and second halves separately\n",
        "first_half = [{'start_date': f'2021-{month}-01', 'end_date': f'2021-{month}-16'} for month in months]\n",
        "second_half = [{'start_date': f'2021-{month}-16', 'end_date': f'2021-{month}-{max_day(month)}'} for month in months]\n",
        "\n",
        "# Combine the first and second halves\n",
        "date_ranges = first_half + second_half\n",
        "\n",
        "# Convert date strings to datetime objects and sort\n",
        "date_ranges.sort(key=lambda x: datetime.strptime(x['start_date'], '%Y-%m-%d'))\n",
        "\n",
        "# Print the sorted date ranges\n",
        "print(date_ranges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi2WQ6t4goIh"
      },
      "source": [
        "### Decadal ranges (decadal averaging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZKB9ojegnqV"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def get_date_ranges(year):\n",
        "    # Define the list of months\n",
        "    months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
        "\n",
        "    # Function to get the maximum day of the month\n",
        "    def max_day(month):\n",
        "        if month in ['01', '03', '05', '07', '08', '10', '12']:\n",
        "            return '31'\n",
        "        elif month == '02':\n",
        "            # Assuming non-leap year for simplicity\n",
        "            return '28' if not year % 4 == 0 or (year % 100 == 0 and year % 400 != 0) else '29'\n",
        "        else:\n",
        "            return '30'\n",
        "\n",
        "    # Create the list comprehension for first, second, and third decades separately\n",
        "    first_decade = [{'start_date': f'{year}-{month}-01', 'end_date': f'{year}-{month}-10'} for month in months]\n",
        "    second_decade = [{'start_date': f'{year}-{month}-11', 'end_date': f'{year}-{month}-20'} for month in months]\n",
        "    third_decade = [{'start_date': f'{year}-{month}-21', 'end_date': f'{year}-{month}-{max_day(month)}'} for month in months]\n",
        "\n",
        "    # Combine the first, second, and third decades\n",
        "    date_ranges = first_decade + second_decade + third_decade\n",
        "\n",
        "    # Convert date strings to datetime objects and sort\n",
        "    date_ranges.sort(key=lambda x: datetime.strptime(x['start_date'], '%Y-%m-%d'))\n",
        "\n",
        "    return date_ranges\n",
        "\n",
        "# Example usage:\n",
        "year = 2021\n",
        "date_ranges = get_date_ranges(year)\n",
        "print(date_ranges)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2BQXujP517"
      },
      "source": [
        "### Phenology Indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05PtFvxYQEbV"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import folium\n",
        "\n",
        "# Initialize the Earth Engine library\n",
        "ee.Initialize()\n",
        "\n",
        "def computeEVI2(image):\n",
        "    \"\"\"Compute the EVI2 index for a given image.\"\"\"\n",
        "    NIR = image.select('B8')  # Assuming NIR band is labeled as B8\n",
        "    red = image.select('B4')  # Assuming red band is labeled as B4\n",
        "    DVI = NIR.subtract(red).rename('DVI')\n",
        "    EVI2 = ee.Image(2.5).multiply(DVI) \\\n",
        "        .divide(NIR.add(ee.Image(2.4).multiply(red)).add(ee.Image(1))).rename('EVI2')\n",
        "    return image.addBands(EVI2)\n",
        "\n",
        "def compute_yearly_sum_EVI2(year):\n",
        "    \"\"\"Compute the pixel-wise sum of EVI2 values >= 0.2 for a given year.\"\"\"\n",
        "    start_date = f'{year}-01-01'\n",
        "    end_date = f'{year}-12-31'\n",
        "\n",
        "    # Load Sentinel-2 image collection for the given year\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate(start_date, end_date).filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 80))\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY').filterBounds(region).filterDate(start_date, end_date)\n",
        "\n",
        "    # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr,\n",
        "        secondary=s2Clouds,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "\n",
        "    def maskClouds(img):\n",
        "        clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "        isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "        return img.updateMask(isNotCloud)\n",
        "\n",
        "    def maskEdges(s2_img):\n",
        "        return s2_img.updateMask(\n",
        "            s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "    # Compute EVI2 for each image and mask EVI2 values below 0.2\n",
        "    def mask_evi2_below_threshold(image):\n",
        "        evi2_image = computeEVI2(image)\n",
        "        evi2 = evi2_image.select('EVI2')\n",
        "        mask = evi2.gte(0.2)\n",
        "        return evi2_image.updateMask(mask)\n",
        "\n",
        "    evi2_collection = s2CloudMasked.map(mask_evi2_below_threshold)\n",
        "\n",
        "    # Sum the EVI2 values for each pixel\n",
        "    evi2_sum = evi2_collection.select('EVI2').sum().rename('EVI2').clip(region)\n",
        "\n",
        "    return evi2_sum\n",
        "\n",
        "# Compute the yearly EVI2 sums for the years 2019-2023 and save them in a list\n",
        "years = [2019, 2020, 2021, 2022, 2023]\n",
        "TP_yearly_list = []\n",
        "\n",
        "for year in years:\n",
        "    evi2_sum = compute_yearly_sum_EVI2(year)\n",
        "    TP_yearly_list.append([evi2_sum, year])\n",
        "    print(f\"Computed EVI2 sum for year {year}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD1dGdLo4dx_"
      },
      "source": [
        "### VIS Phenology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xqbRCU6RQUlU",
        "outputId": "cdab94e8-5077-4094-da28-2056f6008e5b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7896e855e950>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_c8b35c6dfde3c1be7625da3353d2c2c2 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_c8b35c6dfde3c1be7625da3353d2c2c2&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_c8b35c6dfde3c1be7625da3353d2c2c2 = L.map(\n",
              "                &quot;map_c8b35c6dfde3c1be7625da3353d2c2c2&quot;,\n",
              "                {\n",
              "                    center: [52.03, 41.16],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_2cbe31924103baa2ef5eec1cb1ac8636 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_8dcd93a4da653a75ae34cacd0539ffaf = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/e1c114065f31ff75a965b78f6f0b0072-29060e7fe2abee7c627270e7908be3eb/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_6f07ce142a12b5614febaaf766bbb1a2 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/8e659608717bf952af049242aad14a9d-b9e541ad60db2be194f82ae267946e95/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_0c3b67d854aeaf0dd0ad49a2b943def0 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/9060dc56e487d900d8d8d8390e0566df-2b28df410e04519b2b5ec64e93a764f9/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_328d160df2a7a336f1f716f6fd9c250e = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/ab59fd62d60248f7185f998b1272b520-3b8a1e3f1519fa730ce63cef3274795c/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_1c16319f6fb6f84b99fe6e3400387c6c = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/f944115a34b343c538ed0648d392e2e3-8e29bcf214723a47ea90fc600f7fe096/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_3135e188e7d1c98ddc6b7850ae5f07e6 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/295a72da60f55adc1412a6511073f2b5-8219acc9a19620a3f8664ba2b506c8c5/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "            var tile_layer_e33c8a93c44c66c17479cedeb10f4b6f = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/deba34ecbafe4d5a2b3d361b3a56938e-c7cc20964937bb5db468de40c8be0cbf/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "    \n",
              "\n",
              "        function geo_json_50bcbaec9910bdb91082d38c799c50f1_onEachFeature(feature, layer) {\n",
              "            layer.on({\n",
              "            });\n",
              "        };\n",
              "        var geo_json_50bcbaec9910bdb91082d38c799c50f1 = L.geoJson(null, {\n",
              "                onEachFeature: geo_json_50bcbaec9910bdb91082d38c799c50f1_onEachFeature,\n",
              "            \n",
              "        });\n",
              "\n",
              "        function geo_json_50bcbaec9910bdb91082d38c799c50f1_add (data) {\n",
              "            geo_json_50bcbaec9910bdb91082d38c799c50f1\n",
              "                .addData(data)\n",
              "                .addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        }\n",
              "            geo_json_50bcbaec9910bdb91082d38c799c50f1_add({&quot;coordinates&quot;: [[[41.14988226851944, 52.024994286266384], [41.20262280327863, 52.024994286266384], [41.20262280327863, 52.05998970966108], [41.14988226851944, 52.05998970966108], [41.14988226851944, 52.024994286266384]]], &quot;geodesic&quot;: false, &quot;type&quot;: &quot;Polygon&quot;});\n",
              "\n",
              "        \n",
              "    \n",
              "            var layer_control_b0b6a17d272900e627631f09757c8488 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_2cbe31924103baa2ef5eec1cb1ac8636,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;SOS 2020 median&quot; : tile_layer_8dcd93a4da653a75ae34cacd0539ffaf,\n",
              "                    &quot;EOS 2020 Masked median&quot; : tile_layer_6f07ce142a12b5614febaaf766bbb1a2,\n",
              "                    &quot;seasonal amplitude 2020&quot; : tile_layer_0c3b67d854aeaf0dd0ad49a2b943def0,\n",
              "                    &quot;greenup slope 2020&quot; : tile_layer_328d160df2a7a336f1f716f6fd9c250e,\n",
              "                    &quot;greendown slope 2020&quot; : tile_layer_1c16319f6fb6f84b99fe6e3400387c6c,\n",
              "                    &quot;Total Seasonal Productivity 2020&quot; : tile_layer_3135e188e7d1c98ddc6b7850ae5f07e6,\n",
              "                    &quot;Season Duration 2020&quot; : tile_layer_e33c8a93c44c66c17479cedeb10f4b6f,\n",
              "                    &quot;ROI&quot; : geo_json_50bcbaec9910bdb91082d38c799c50f1,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_b0b6a17d272900e627631f09757c8488.base_layers,\n",
              "                layer_control_b0b6a17d272900e627631f09757c8488.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_c8b35c6dfde3c1be7625da3353d2c2c2);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import folium\n",
        "import ee\n",
        "\n",
        "k = 1\n",
        "j = 2019+k\n",
        "\n",
        "# Define the visualization parameters\n",
        "SOSVIS = {'min': 0, 'max': 365, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red']}\n",
        "EOSVIS = {'min': 0, 'max': 365, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red']}\n",
        "TPVIS = {'min': 0, 'max': 2500, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red']}\n",
        "\n",
        "IndVIS = {'min': 0, 'max': 2.5, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red']}\n",
        "curveVIS = {'min': 0, 'max': 0.05, 'bands':'EVI2', 'palette': ['cyan', 'green', 'yellow', 'orange', 'red']}\n",
        "\n",
        "# Create a Folium map centered around your region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Get the map ID for the EVI2 image\n",
        "'''\n",
        "map_id = result_image.getMapId(SOSVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='EVI2 Masked',\n",
        ").add_to(map)\n",
        "'''\n",
        "map_id2 = SOS_yearly_list[k][1].getMapId(SOSVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id2['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'SOS {j} median',\n",
        ").add_to(map)\n",
        "\n",
        "map_id3 = EOS_yearly_list[k][1].getMapId(SOSVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id3['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'EOS {j} Masked median',\n",
        ").add_to(map)\n",
        "\n",
        "map_id5 = Seasamp_yearly_list[k][1].getMapId(IndVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id5['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'seasonal amplitude {j}',\n",
        ").add_to(map)\n",
        "\n",
        "map_id6 = greenup_yearly_list[k][1].getMapId(curveVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id6['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'greenup slope {j}',\n",
        ").add_to(map)\n",
        "\n",
        "map_id7 = greendown_yearly_list[k][1].getMapId(curveVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id7['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'greendown slope {j}',\n",
        ").add_to(map)\n",
        "\n",
        "map_id8 = TP_yearly_list[k][0].getMapId(TPVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id8['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'Total Seasonal Productivity {j}',\n",
        ").add_to(map)\n",
        "\n",
        "map_id9 = season_length_list[k][0].getMapId(EOSVIS)\n",
        "\n",
        "# Add the EVI2 image as a tile layer to the map\n",
        "folium.TileLayer(\n",
        "    tiles=map_id9['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name=f'Season Duration {j}',\n",
        ").add_to(map)\n",
        "\n",
        "\n",
        "\n",
        "roi_geojson = region.getInfo()\n",
        "folium.GeoJson(roi_geojson, name='ROI').add_to(map)\n",
        "\n",
        "# Add layer control to the map\n",
        "folium.LayerControl().add_to(map)\n",
        "\n",
        "# Display the map\n",
        "map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6V1TyqsVr7o"
      },
      "source": [
        "### Compute and export PPI for given START_DATE, END_DATE, least cloudy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9kHMV2OVr_Z"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "\n",
        "# Define the desired date range\n",
        "START_DATE = ee.Date('2021-10-01')\n",
        "END_DATE = ee.Date('2021-12-01')\n",
        "\n",
        "# Filter the image collection by date range\n",
        "filtered_collection = s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate(START_DATE, END_DATE)\n",
        "\n",
        "# Sort the filtered collection by cloud cover\n",
        "sorted_collection = filtered_collection.sort('CLOUDY_PIXEL_PERCENTAGE')\n",
        "\n",
        "# Select the image with the lowest cloud cover\n",
        "selected_image = ee.Image(sorted_collection.first())\n",
        "date = selected_image.date().format('YYYY-MM-dd').getInfo()\n",
        "\n",
        "selected_image = compute_PPI(selected_image)\n",
        "# Define the export parameters\n",
        "\n",
        "export_params = {\n",
        "    'image': selected_image.select(['PPI']),\n",
        "    'description': f'lowest_cloud_cover_image {date}',\n",
        "    'folder': 'GEE_images',  # Replace 'your_folder_name' with your desired folder name\n",
        "    'scale': 10,  # Adjust the scale as needed\n",
        "    'region': region,  # Define the region of interest\n",
        "}\n",
        "\n",
        "# Export the image to your Google Drive\n",
        "task = ee.batch.Export.image.toDrive(**export_params)\n",
        "task.start()\n",
        "\n",
        "# Print the task status\n",
        "print('Exporting image with lowest cloud cover to Google Drive...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfeC-SyPakkB"
      },
      "source": [
        "## SOS Yearly (2021) Median + Median images decadal calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSXDclHIaknu"
      },
      "outputs": [],
      "source": [
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "#EVI threshold\n",
        "threshold = 0.35\n",
        "\n",
        "def map_SOS_EOS(image):\n",
        "    SOS, EOS = find_SOS_EOS(image, threshold=0.2)\n",
        "    return image.addBands(SOS.rename('SOS')).addBands(EOS.rename('EOS'))\n",
        "\n",
        "#DVImax_yearly = compute_yearly_DVImax(s2Sr)\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "SOS_median = ee.Image.constant(0)\n",
        "\n",
        "full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "for date_range in date_ranges: #phenology season\n",
        "    START_DATE = ee.Date(date_range['start_date'])\n",
        "    END_DATE = ee.Date(date_range['end_date'])\n",
        "    middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "    # Filter images by date range and region\n",
        "    criteria_a = ee.Filter.And(\n",
        "        ee.Filter.bounds(region),\n",
        "        ee.Filter.date(START_DATE, END_DATE))\n",
        "    criteria_b = ee.Filter.And(\n",
        "        ee.Filter.bounds(region),\n",
        "        ee.Filter.date(START_DATE, END_DATE),\n",
        "        ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "    s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "    s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "    # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr_filtered,\n",
        "        secondary=s2Clouds_filtered,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "    s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "    PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "    rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "    images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "    EVI2_images = []\n",
        "\n",
        "    try:\n",
        "        for i in range(images.size().getInfo()):\n",
        "\n",
        "            image = ee.Image(images.get(i))\n",
        "            date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "            # Compute PPI for the image\n",
        "            EVI2_image = computeEVI2(image)\n",
        "            EVI2_images.append(EVI2_image)\n",
        "\n",
        "        EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "\n",
        "        # Define the threshold for the seasonal amplitude\n",
        "        threshold = seas_amp_median.multiply(0.25)\n",
        "\n",
        "        # Compute the median EVI2 image for the entire date range\n",
        "        median_EVI2_image = EVI2_collection.median()\n",
        "\n",
        "        # Mask the median EVI2 image based on the thresholded seasonal amplitude\n",
        "        masked_median_EVI2_image = median_EVI2_image.updateMask(seas_amp_median.gt(threshold))\n",
        "\n",
        "        masked_median_EVI2_image = masked_median_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "        day_of_year = ee.Date(masked_median_EVI2_image.getInfo()['properties']['system:time_start']).difference(ee.Date('2021-01-01'), 'days').round()\n",
        "\n",
        "        # Create a constant image representing the day of year\n",
        "        constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "        # Update the result image to store the start-of-season day for each pixel\n",
        "        SOS_median = SOS_median.where(SOS_median.eq(0).And(masked_median_EVI2_image.select('EVI2').gt(threshold)), constant_day)\n",
        "\n",
        "\n",
        "        full_EVI2_collection = full_EVI2_collection.merge(median_EVI2_image)\n",
        "\n",
        "    except:\n",
        "      print('exception')\n",
        "      pass\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY9nOeUwuwXJ"
      },
      "source": [
        "## EOS 2021 non-median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OcmIs-H9BuL"
      },
      "outputs": [],
      "source": [
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "#EVI threshold\n",
        "threshold = 0.35\n",
        "\n",
        "def map_SOS_EOS(image):\n",
        "    SOS, EOS = find_SOS_EOS(image, threshold=0.2)\n",
        "    return image.addBands(SOS.rename('SOS')).addBands(EOS.rename('EOS'))\n",
        "\n",
        "#DVImax_yearly = compute_yearly_DVImax(s2Sr)\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "SOS_median = ee.Image.constant(0)\n",
        "\n",
        "full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "for date_range in date_ranges[9:30]: #phenology season\n",
        "    START_DATE = ee.Date(date_range['start_date'])\n",
        "    END_DATE = ee.Date(date_range['end_date'])\n",
        "    middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "    # Filter images by date range and region\n",
        "    criteria_a = ee.Filter.And(\n",
        "        ee.Filter.bounds(region),\n",
        "        ee.Filter.date(START_DATE, END_DATE))\n",
        "    criteria_b = ee.Filter.And(\n",
        "        ee.Filter.bounds(region),\n",
        "        ee.Filter.date(START_DATE, END_DATE),\n",
        "        ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "    s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "    s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "    # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr_filtered,\n",
        "        secondary=s2Clouds_filtered,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "    s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "    PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "    rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "    if s2CloudMaskedWithNDSI.size().getInfo() > 0:\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        for i in range(images.size().getInfo()):\n",
        "\n",
        "            image = ee.Image(images.get(i))\n",
        "            date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "            # Compute PPI for the image\n",
        "            EVI2_image = computeEVI2(image)\n",
        "\n",
        "\n",
        "\n",
        "            # Define the threshold for the seasonal amplitude\n",
        "            threshold = seas_amp_median.multiply(0.25)\n",
        "\n",
        "            # Mask the median EVI2 image based on the thresholded seasonal amplitude\n",
        "            masked_EVI2_image = EVI2_image.updateMask(seas_amp_median.gt(threshold))\n",
        "\n",
        "            masked_EVI2_image = masked_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "            day_of_year = ee.Date(masked_EVI2_image.getInfo()['properties']['system:time_start']).difference(ee.Date('2021-01-01'), 'days').round()\n",
        "\n",
        "            # Create a constant image representing the day of year\n",
        "            constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "            # Update the result image to store the start-of-season day for each pixel\n",
        "            SOS_median = SOS_median.where(SOS_median.eq(0).And(masked_EVI2_image.select('EVI2').gt(threshold)), constant_day)\n",
        "\n",
        "            '''\n",
        "            full_EVI2_collection = full_EVI2_collection.merge(median_EVI2_image)\n",
        "            '''\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxR0IV6ly3UI"
      },
      "source": [
        "## EOS yearly (2021) median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Jk9rVPtny2og",
        "outputId": "841aa7d3-8a3a-47d3-d73c-ae2d09124553"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "def map_SOS_EOS(image):\n",
        "    SOS, EOS = find_SOS_EOS(image, threshold=0.2)\n",
        "    return image.addBands(SOS.rename('SOS')).addBands(EOS.rename('EOS'))\n",
        "\n",
        "#DVImax_yearly = compute_yearly_DVImax(s2Sr)\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "EOS_median = ee.Image.constant(0)\n",
        "\n",
        "for date_range in date_ranges[12:]: #phenology season\n",
        "    START_DATE = ee.Date(date_range['start_date'])\n",
        "    END_DATE = ee.Date(date_range['end_date'])\n",
        "    middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "    # Filter images by date range and region\n",
        "    criteria_a = ee.Filter.And(\n",
        "        ee.Filter.bounds(region),\n",
        "        ee.Filter.date(START_DATE, END_DATE))\n",
        "    criteria_b = ee.Filter.And(\n",
        "        ee.Filter.bounds(region),\n",
        "        ee.Filter.date(START_DATE, END_DATE),\n",
        "        ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "    s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "    s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "    # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr_filtered,\n",
        "        secondary=s2Clouds_filtered,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "    s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "    PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "    rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "    images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "    EVI2_images = []\n",
        "\n",
        "    try:\n",
        "        for i in range(images.size().getInfo()):\n",
        "\n",
        "            image = ee.Image(images.get(i))\n",
        "            date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "            # Compute PPI for the image\n",
        "            EVI2_image  = computeEVI2(image)\n",
        "            EVI2_images.append(EVI2_image)\n",
        "\n",
        "        EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "        threshold = seas_amp_median.multiply(0.15)\n",
        "\n",
        "        # Calculate the median EVI2 image for the entire date range\n",
        "        median_EVI2_image = EVI2_collection.median()\n",
        "\n",
        "        # Mask the median EVI2 image\n",
        "        masked_median_EVI2_image = median_EVI2_image.updateMask(seas_amp_median.gt(threshold))\n",
        "\n",
        "        masked_median_EVI2_image = masked_median_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "        day_of_year = ee.Date(masked_median_EVI2_image.getInfo()['properties']['system:time_start']).difference(ee.Date('2021-01-01'), 'days').round()\n",
        "        constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "        # Update the result image\n",
        "        EOS_median = EOS_median.where((masked_median_EVI2_image.select('EVI2').gt(threshold)), constant_day)\n",
        "\n",
        "        negative_condition = EOS_median.lte(0)\n",
        "\n",
        "        # Get the maximum EOS value\n",
        "        max_EOS_value = EOS_median.reduceRegion(\n",
        "            reducer=ee.Reducer.max(),\n",
        "            geometry=region,\n",
        "            scale=10\n",
        "        ).get('constant')\n",
        "\n",
        "        max_EOS_constant = ee.Image.constant(max_EOS_value)\n",
        "\n",
        "        # Set EOS_median to the maximum EOS value where it is negative\n",
        "        EM = EOS_median.where(negative_condition, max_EOS_constant)\n",
        "\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXmOM4WHFfJF"
      },
      "source": [
        "## Seasonal amplitude yearly (2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8WHuTq95FfNy",
        "outputId": "63468dc9-432b-457c-8a05-02f3ef3a7cef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2021-01-01', '2021-12-31').filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50))\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY').filterBounds(region).filterDate('2021-01-01', '2021-12-31')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr,\n",
        "        secondary=s2Clouds,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "def seasonal_amplitude(collection):\n",
        "    EVI_collection = collection.map(computeEVI2)\n",
        "    EVImax = EVI_collection.select('EVI2').reduce(ee.Reducer.max()).rename('EVImax')\n",
        "    EVImin = EVI_collection.select('EVI2').reduce(ee.Reducer.min()).rename('EVImin')\n",
        "\n",
        "\n",
        "    return EVImax.subtract(EVImin)\n",
        "\n",
        "seas_amp = seasonal_amplitude(s2Sr)\n",
        "seas_amp_median = seasonal_amplitude(full_EVI2_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLSnL0nd_HPg"
      },
      "source": [
        "## Slope of the Green-up Period (2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "sJmhNgIh_GjG",
        "outputId": "a6383822-6962-4952-c6b9-f2f74d9978b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_0bf6904ceeadb7fe418a4b4f0771b6af {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_0bf6904ceeadb7fe418a4b4f0771b6af&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_0bf6904ceeadb7fe418a4b4f0771b6af = L.map(\n",
              "                &quot;map_0bf6904ceeadb7fe418a4b4f0771b6af&quot;,\n",
              "                {\n",
              "                    center: [0.0, 0.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 2,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_918be8470956ff7a97bcbee633782839 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_0bf6904ceeadb7fe418a4b4f0771b6af);\n",
              "        \n",
              "    \n",
              "        function geo_json_a996cddd48575487090e445cab9ace25_styler(feature) {\n",
              "            switch(feature.id) {\n",
              "                default:\n",
              "                    return {&quot;color&quot;: &quot;blue&quot;, &quot;fillColor&quot;: &quot;transparent&quot;, &quot;weight&quot;: 2};\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function geo_json_a996cddd48575487090e445cab9ace25_onEachFeature(feature, layer) {\n",
              "            layer.on({\n",
              "            });\n",
              "        };\n",
              "        var geo_json_a996cddd48575487090e445cab9ace25 = L.geoJson(null, {\n",
              "                onEachFeature: geo_json_a996cddd48575487090e445cab9ace25_onEachFeature,\n",
              "            \n",
              "                style: geo_json_a996cddd48575487090e445cab9ace25_styler,\n",
              "        });\n",
              "\n",
              "        function geo_json_a996cddd48575487090e445cab9ace25_add (data) {\n",
              "            geo_json_a996cddd48575487090e445cab9ace25\n",
              "                .addData(data)\n",
              "                .addTo(map_0bf6904ceeadb7fe418a4b4f0771b6af);\n",
              "        }\n",
              "            geo_json_a996cddd48575487090e445cab9ace25_add({&quot;features&quot;: [{&quot;geometry&quot;: {&quot;coordinates&quot;: [[[41.14988226851944, 52.024994286266384], [41.20262280327863, 52.024994286266384], [41.20262280327863, 52.05998970966108], [41.14988226851944, 52.05998970966108], [41.14988226851944, 52.024994286266384]]], &quot;geodesic&quot;: false, &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
              "\n",
              "        \n",
              "    \n",
              "            geo_json_a996cddd48575487090e445cab9ace25.bindTooltip(\n",
              "                `&lt;div&gt;\n",
              "                     Region of Interest\n",
              "                 &lt;/div&gt;`,\n",
              "                {&quot;sticky&quot;: true}\n",
              "            );\n",
              "        \n",
              "    \n",
              "            var tile_layer_e2576b3ec71f6d03930a30066d672500 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1/projects/ee-shrgnn/maps/68e6de35fa25620975851a4590340a27-82d0a904452fef326dee1b0722176aa4/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Google Earth Engine&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_0bf6904ceeadb7fe418a4b4f0771b6af);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7b4eeda8eb00>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import folium\n",
        "import ee\n",
        "\n",
        "# Initialize the Earth Engine library\n",
        "ee.Initialize()\n",
        "\n",
        "# Define the region of interest\n",
        "region = region\n",
        "\n",
        "# Define the date ranges around 15th April and 15th May\n",
        "april_start = ee.Date('2021-04-08')\n",
        "april_end = ee.Date('2021-04-22')\n",
        "may_start = ee.Date('2021-05-08')\n",
        "may_end = ee.Date('2021-05-22')\n",
        "\n",
        "# Define the image collection and filter by date and cloud cover\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterBounds(region) \\\n",
        "    .filter(ee.Filter.date(april_start, april_end)) \\\n",
        "    .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50)) \\\n",
        "    .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "    .limit(1)\n",
        "\n",
        "s2SrMay = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterBounds(region) \\\n",
        "    .filter(ee.Filter.date(may_start, may_end)) \\\n",
        "    .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50)) \\\n",
        "    .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "    .limit(1)\n",
        "\n",
        "# Compute PPI for April\n",
        "s2Sr_April = s2Sr.map(computeEVI2).median()\n",
        "\n",
        "# Compute PPI for May\n",
        "s2Sr_May = s2SrMay.map(computeEVI2).median()\n",
        "\n",
        "# Compute the difference in PPI values between April and May\n",
        "diff_PPI = s2Sr_May.subtract(s2Sr_April)\n",
        "\n",
        "april_date = s2Sr.first().date()\n",
        "may_date = s2SrMay.first().date()\n",
        "\n",
        "# Compute the number of days between the images\n",
        "num_days = may_date.difference(april_date, 'days')\n",
        "\n",
        "# Divide the difference in PPI values by the number of days between the two dates\n",
        "slope_greenup = diff_PPI.divide(num_days)\n",
        "\n",
        "# Create a color map from green to red\n",
        "cmap = ['00FF00', '#ffff00', 'FF0000']\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[0, 0], zoom_start=2)\n",
        "\n",
        "# Add the region of interest to the map\n",
        "folium.GeoJson(\n",
        "    data=region.getInfo(),\n",
        "    name='Region of Interest',\n",
        "    style_function=lambda x: {'fillColor': 'transparent', 'color': 'blue', 'weight': 2},\n",
        "    tooltip='Region of Interest'\n",
        ").add_to(map)\n",
        "\n",
        "# Add the slope_greenup image to the map\n",
        "mapid = slope_greenup.select(['EVI2']).getMapId({'min': 0, 'max': 0.05, 'palette': cmap})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    name='slope_greenup',\n",
        ").add_to(map)\n",
        "\n",
        "# Display the map\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giLCnLSQHptM"
      },
      "source": [
        "## Slope of the Green-up Period 2019-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2BMKbu67xLM"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "import ee\n",
        "\n",
        "# Initialize the Earth Engine library\n",
        "ee.Initialize()\n",
        "\n",
        "# Define the date ranges around 15th April and 15th May\n",
        "april_start_base = ee.Date('2021-04-02')\n",
        "april_end_base = ee.Date('2021-04-25')\n",
        "may_start_base = ee.Date('2021-05-06')\n",
        "may_end_base = ee.Date('2021-05-29')\n",
        "\n",
        "# Create a color map from green to red\n",
        "cmap = ['00FF00', '#ffff00', 'FF0000']\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Initialize an empty image to accumulate slope_greenup values\n",
        "slope_greenup_accumulated = ee.Image.constant(0)\n",
        "\n",
        "# Initialize a counter for the number of years\n",
        "num_years = 0\n",
        "\n",
        "greenup_yearly_list = []\n",
        "\n",
        "# Loop over years from 2018 to 2024\n",
        "for year in range(2019, 2024):\n",
        "    # Increment the start dates by one year\n",
        "    april_start = april_start_base.advance(year - 2021, 'year')\n",
        "    april_end = april_end_base.advance(year - 2021, 'year')\n",
        "    may_start = may_start_base.advance(year - 2021, 'year')\n",
        "    may_end = may_end_base.advance(year - 2021, 'year')\n",
        "\n",
        "    may_end_str = may_end.format('YYYY-MM-dd').getInfo()\n",
        "\n",
        "    # Define the image collection and filter by date and cloud cover for April\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "        .filterBounds(region) \\\n",
        "        .filter(ee.Filter.date(april_start, april_end)) \\\n",
        "        .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50)) \\\n",
        "        .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "        .limit(1)\n",
        "\n",
        "    # Define the image collection and filter by date and cloud cover for May\n",
        "    s2SrMay = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "        .filterBounds(region) \\\n",
        "        .filter(ee.Filter.date(may_start, may_end)) \\\n",
        "        .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50)) \\\n",
        "        .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "        .limit(1)\n",
        "\n",
        "    # Compute PPI for April\n",
        "    s2Sr_April = s2Sr.map(computeEVI2).median()\n",
        "\n",
        "    # Compute PPI for May\n",
        "    s2Sr_May = s2SrMay.map(computeEVI2).median()\n",
        "\n",
        "    # Compute the difference in PPI values between April and May\n",
        "    diff_PPI = s2Sr_May.subtract(s2Sr_April)\n",
        "\n",
        "    # Get the dates of the images in s2Sr and s2SrMay\n",
        "    april_date = s2Sr.first().date()\n",
        "    may_date = s2SrMay.first().date()\n",
        "\n",
        "    # Compute the number of days between the images\n",
        "    num_days = may_date.difference(april_date, 'days')\n",
        "    print(year)\n",
        "\n",
        "    # Divide the difference in PPI values by the number of days between the two dates\n",
        "    slope_greenup = diff_PPI.divide(num_days)\n",
        "    # Add the slope_greenup image to the map with year and dates in the title\n",
        "    mapid = slope_greenup.select(['EVI2']).getMapId({'min': 0, 'max': 0.05, 'palette': cmap})\n",
        "    folium.TileLayer(\n",
        "        tiles=mapid['tile_fetcher'].url_format,\n",
        "        attr='Google Earth Engine',\n",
        "        overlay=True,\n",
        "        name=f'slope_greenup_{year}_{april_date.format(\"YYYY-MM-dd\").getInfo()}_{may_date.format(\"YYYY-MM-dd\").getInfo()}',\n",
        "    ).add_to(map)\n",
        "\n",
        "    slope_greenup_accumulated = slope_greenup_accumulated.add(slope_greenup)\n",
        "\n",
        "    num_years += 1\n",
        "\n",
        "    greenup_yearly_list.append([year, slope_greenup])\n",
        "\n",
        "mean_slope_greenup = slope_greenup_accumulated.divide(num_years)\n",
        "\n",
        "mapid2 = mean_slope_greenup.select(['EVI2']).getMapId({'min': 0, 'max': 0.05, 'palette': cmap})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid2['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    name=f'mean_slope_greenup_all_years',\n",
        ").add_to(map)\n",
        "\n",
        "\n",
        "roi_geojson = region.getInfo()\n",
        "folium.GeoJson(roi_geojson, name='ROI').add_to(map)\n",
        "\n",
        "folium.LayerControl().add_to(map)\n",
        "\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UyuyaFC_Rko"
      },
      "source": [
        "## Slope of the Green-down Period (2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OONom8vA_Rpk"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "import ee\n",
        "\n",
        "# Initialize the Earth Engine library\n",
        "ee.Initialize()\n",
        "\n",
        "# Define the region of interest\n",
        "region = region\n",
        "\n",
        "# Define the date ranges around 15th April and 15th May\n",
        "november_start = ee.Date('2021-10-11')\n",
        "november_end = ee.Date('2021-11-25')\n",
        "december_start = ee.Date('2021-12-01')\n",
        "december_end = ee.Date('2021-12-31')\n",
        "\n",
        "# Define the image collection and filter by date and cloud cover\n",
        "s2Sr_november_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterBounds(region) \\\n",
        "    .filter(ee.Filter.date(april_start, april_end)) \\\n",
        "    .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50)) \\\n",
        "    .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "    .limit(1)\n",
        "\n",
        "s2Sr_december_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterBounds(region) \\\n",
        "    .filter(ee.Filter.date(may_start, may_end)) \\\n",
        "    .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50)) \\\n",
        "    .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "    .limit(1)\n",
        "\n",
        "# Compute PPI for April\n",
        "s2Sr_november = s2Sr.map(computeEVI2).median()\n",
        "\n",
        "# Compute PPI for May\n",
        "s2Sr_december = s2SrMay.map(computeEVI2).median()\n",
        "\n",
        "# Compute the difference in PPI values between April and May\n",
        "diff_PPI = s2Sr_november.subtract(s2Sr_december)\n",
        "\n",
        "november_date = s2Sr_november_col.first().date()\n",
        "december_date = s2Sr_december_col.first().date()\n",
        "\n",
        "# Compute the number of days between the images\n",
        "num_days = december_date.difference(november_date, 'days')\n",
        "\n",
        "# Divide the difference in PPI values by the number of days between the two dates\n",
        "slope_greendown = diff_PPI.divide(num_days)\n",
        "\n",
        "# Create a color map from green to red\n",
        "cmap = ['00FF00', '#ffff00', 'FF0000']\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[0, 0], zoom_start=2)\n",
        "\n",
        "# Add the region of interest to the map\n",
        "folium.GeoJson(\n",
        "    data=region.getInfo(),\n",
        "    name='Region of Interest',\n",
        "    style_function=lambda x: {'fillColor': 'transparent', 'color': 'blue', 'weight': 2},\n",
        "    tooltip='Region of Interest'\n",
        ").add_to(map)\n",
        "\n",
        "# Add the slope_greenup image to the map\n",
        "mapid = slope_greendown.select(['EVI2']).getMapId({'min': 0, 'max': 0.1, 'palette': cmap})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    name='slope_greenup',\n",
        ").add_to(map)\n",
        "\n",
        "# Display the map\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQqIsNgbALk-"
      },
      "source": [
        "## Slope of the Green-down Period 2019-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtIR5H-aAL8P"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "import ee\n",
        "\n",
        "# Initialize the Earth Engine library\n",
        "ee.Initialize()\n",
        "\n",
        "# Define the region of interest\n",
        "region = region\n",
        "\n",
        "# Define the date ranges around 15th November and 15th December\n",
        "november_start_base = ee.Date('2021-09-15')\n",
        "november_end_base = ee.Date('2021-10-15')\n",
        "december_start_base = ee.Date('2021-11-01')\n",
        "december_end_base = ee.Date('2021-12-01')\n",
        "\n",
        "# Create a color map from green to red\n",
        "cmap = ['00FF00', '#ffff00', 'FF0000']\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=6)\n",
        "\n",
        "# Initialize an empty image to accumulate slope_greendown values\n",
        "slope_greendown_accumulated = ee.Image.constant(0)\n",
        "\n",
        "# Initialize a counter for the number of years\n",
        "num_years = 0\n",
        "\n",
        "greendown_yearly_list = []\n",
        "\n",
        "# Loop over years from 2019 to 2023\n",
        "for year in range(2019, 2024):\n",
        "    # Increment the start dates by one year\n",
        "    november_start = november_start_base.advance(year - 2021, 'year')\n",
        "    november_end = november_end_base.advance(year - 2021, 'year')\n",
        "    december_start = december_start_base.advance(year - 2021, 'year')\n",
        "    december_end = december_end_base.advance(year - 2021, 'year')\n",
        "\n",
        "    # Define the image collection and filter by date and cloud cover for November\n",
        "    s2Sr_november_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "        .filterBounds(region) \\\n",
        "        .filter(ee.Filter.date(november_start, november_end)) \\\n",
        "        .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 65)) \\\n",
        "        .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "        .limit(1)\n",
        "\n",
        "    # Define the image collection and filter by date and cloud cover for December\n",
        "    s2Sr_december_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "        .filterBounds(region) \\\n",
        "        .filter(ee.Filter.date(december_start, december_end)) \\\n",
        "        .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 65)) \\\n",
        "        .sort('CLOUDY_PIXEL_PERCENTAGE', True) \\\n",
        "        .limit(1)\n",
        "\n",
        "    # Compute PPI for November\n",
        "    s2Sr_november = s2Sr_november_col.map(computeEVI2).median()\n",
        "\n",
        "    # Compute PPI for December\n",
        "    s2Sr_december = s2Sr_december_col.map(computeEVI2).median()\n",
        "\n",
        "    # Compute the difference in PPI values between November and December\n",
        "    diff_PPI = s2Sr_november.subtract(s2Sr_december)\n",
        "\n",
        "    # Get the dates of the images in s2Sr_november and s2Sr_december\n",
        "    november_date = s2Sr_november_col.first().date()\n",
        "    december_date = s2Sr_december_col.first().date()\n",
        "\n",
        "    # Compute the number of days between the images\n",
        "    num_days = december_date.difference(november_date, 'days')\n",
        "\n",
        "    # Divide the difference in PPI values by the number of days between the two dates\n",
        "    slope_greendown = diff_PPI.divide(num_days)\n",
        "\n",
        "    # Add the slope_greendown image to the map with year and dates in the title\n",
        "    mapid = slope_greendown.select(['EVI2']).getMapId({'min': 0, 'max': 0.05, 'palette': cmap})\n",
        "    folium.TileLayer(\n",
        "        tiles=mapid['tile_fetcher'].url_format,\n",
        "        attr='Google Earth Engine',\n",
        "        overlay=True,\n",
        "        name=f'slope_greendown_{year}_{november_date.format(\"YYYY-MM-dd\").getInfo()}_{december_date.format(\"YYYY-MM-dd\").getInfo()}',\n",
        "    ).add_to(map)\n",
        "\n",
        "    slope_greendown_accumulated = slope_greendown_accumulated.add(slope_greendown)\n",
        "\n",
        "    num_years += 1\n",
        "\n",
        "    greendown_yearly_list.append([year, slope_greendown])\n",
        "\n",
        "# Compute the mean slope_greendown over all years\n",
        "mean_slope_greendown = slope_greendown_accumulated.divide(num_years)\n",
        "\n",
        "# Add the mean slope_greendown image to the map\n",
        "mapid2 = mean_slope_greendown.select(['EVI2']).getMapId({'min': 0, 'max': 0.05, 'palette': cmap})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid2['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    name=f'mean_slope_greendown_all_years',\n",
        ").add_to(map)\n",
        "\n",
        "# Add the region of interest to the map\n",
        "folium.GeoJson(\n",
        "    data=region.getInfo(),\n",
        "    name='Region of Interest',\n",
        "    style_function=lambda x: {'fillColor': 'transparent', 'color': 'blue', 'weight': 2},\n",
        "    tooltip='Region of Interest'\n",
        ").add_to(map)\n",
        "\n",
        "# Add layer control to the map\n",
        "folium.LayerControl().add_to(map)\n",
        "\n",
        "# Display the map\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmoO7kL4vFTf"
      },
      "source": [
        "## SOS Medians 2019-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ewe4GTmojHi3"
      },
      "outputs": [],
      "source": [
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "\n",
        "#BLOCK1\n",
        "\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "def map_SOS_EOS(image):\n",
        "    SOS, EOS = find_SOS_EOS(image, threshold=0.2)\n",
        "    return image.addBands(SOS.rename('SOS')).addBands(EOS.rename('EOS'))\n",
        "\n",
        "#DVImax_yearly = compute_yearly_DVImax(s2Sr)\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "#BLOCK2\n",
        "\n",
        "SOS_yearly_list = []\n",
        "\n",
        "for year in [2019, 2020, 2021, 2022, 2023]:\n",
        "\n",
        "    date_ranges = get_date_ranges(year)\n",
        "\n",
        "    SOS_median = ee.Image.constant(0)\n",
        "\n",
        "    full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "    for date_range in date_ranges: #phenology season\n",
        "        START_DATE = ee.Date(date_range['start_date'])\n",
        "        END_DATE = ee.Date(date_range['end_date'])\n",
        "        middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "        # Filter images by date range and region\n",
        "        criteria_a = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE))\n",
        "        criteria_b = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "        s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "        s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "        # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "        s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr_filtered,\n",
        "            secondary=s2Clouds_filtered,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "        s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "        s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "        PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "        rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        try:\n",
        "            for i in range(images.size().getInfo()):\n",
        "\n",
        "                image = ee.Image(images.get(i))\n",
        "                date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "                # Compute PPI for the image\n",
        "                EVI2_image = computeEVI2(image)\n",
        "                EVI2_images.append(EVI2_image)\n",
        "\n",
        "            EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "            full_EVI2_collection = full_EVI2_collection.merge(median_EVI2_image)\n",
        "\n",
        "        except:\n",
        "          print('exception, block 2', date_range)\n",
        "          pass\n",
        "\n",
        "    #BLOCK3\n",
        "\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate(f'{year}-01-01', f'{year}-12-31').filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50))\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY').filterBounds(region).filterDate(f'{year}-01-01', f'{year}-12-31')\n",
        "    MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr,\n",
        "            secondary=s2Clouds,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "    def seasonal_amplitude(collection):\n",
        "        EVI_collection = collection.map(computeEVI2)\n",
        "        EVImax = EVI_collection.select('EVI2').reduce(ee.Reducer.max()).rename('EVImax')\n",
        "        EVImin = EVI_collection.select('EVI2').reduce(ee.Reducer.min()).rename('EVImin')\n",
        "\n",
        "\n",
        "        return EVImax.subtract(EVImin)\n",
        "\n",
        "    seas_amp = seasonal_amplitude(s2Sr)\n",
        "    seas_amp_median = seasonal_amplitude(full_EVI2_collection)\n",
        "\n",
        "    #BLOCK4\n",
        "\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "    MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "    SOS_median = ee.Image.constant(0)\n",
        "\n",
        "    full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "    for date_range in date_ranges: #phenology season\n",
        "        START_DATE = ee.Date(date_range['start_date'])\n",
        "        END_DATE = ee.Date(date_range['end_date'])\n",
        "        middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "        # Filter images by date range and region\n",
        "        criteria_a = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE))\n",
        "        criteria_b = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "        s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "        s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "        # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "        s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr_filtered,\n",
        "            secondary=s2Clouds_filtered,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "        s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "        s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "        PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "        rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        try:\n",
        "            for i in range(images.size().getInfo()):\n",
        "\n",
        "                image = ee.Image(images.get(i))\n",
        "                date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "                # Compute PPI for the image\n",
        "                EVI2_image = computeEVI2(image)\n",
        "                EVI2_images.append(EVI2_image)\n",
        "\n",
        "            EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "            # Define the threshold for the seasonal amplitude\n",
        "            threshold = seas_amp_median.multiply(0.25)\n",
        "\n",
        "            # Compute the median EVI2 image for the entire date range\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "\n",
        "            # Mask the median EVI2 image based on the thresholded seasonal amplitude\n",
        "            masked_median_EVI2_image = median_EVI2_image.updateMask(seas_amp_median.gt(threshold))\n",
        "\n",
        "            masked_median_EVI2_image = masked_median_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "            day_of_year = ee.Date(masked_median_EVI2_image.getInfo()['properties']['system:time_start']).difference(ee.Date(f'{year}-01-01'), 'days').round()\n",
        "\n",
        "            # Create a constant image representing the day of year\n",
        "            constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "            # Update the result image to store the start-of-season day for each pixel\n",
        "            SOS_median = SOS_median.where(SOS_median.eq(0).And(masked_median_EVI2_image.select('EVI2').gt(threshold)), constant_day)\n",
        "\n",
        "\n",
        "            full_EVI2_collection = full_EVI2_collection.merge(median_EVI2_image)\n",
        "\n",
        "        except:\n",
        "          print('exception, block 4', date_range)\n",
        "          pass\n",
        "\n",
        "    SOS_yearly_list.append([year,SOS_median])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOoA0dKVZ4j1"
      },
      "source": [
        "## EOS Medians 2019-2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-2Nocf0Z4pp"
      },
      "outputs": [],
      "source": [
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "\n",
        "#BLOCK1\n",
        "\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "def map_SOS_EOS(image):\n",
        "    SOS, EOS = find_SOS_EOS(image, threshold=0.2)\n",
        "    return image.addBands(SOS.rename('SOS')).addBands(EOS.rename('EOS'))\n",
        "\n",
        "#DVImax_yearly = compute_yearly_DVImax(s2Sr)\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "#BLOCK2\n",
        "\n",
        "EOS_yearly_list = []\n",
        "\n",
        "Seasamp_yearly_list = []\n",
        "\n",
        "for year in [2019, 2020, 2021, 2022, 2023]:\n",
        "\n",
        "    date_ranges = get_date_ranges(year)\n",
        "\n",
        "    EOS_median = ee.Image.constant(0)\n",
        "\n",
        "    full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "    for date_range in date_ranges: #phenology season\n",
        "        START_DATE = ee.Date(date_range['start_date'])\n",
        "        END_DATE = ee.Date(date_range['end_date'])\n",
        "        middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "        # Filter images by date range and region\n",
        "        criteria_a = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE))\n",
        "        criteria_b = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "        s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "        s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "        # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "        s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr_filtered,\n",
        "            secondary=s2Clouds_filtered,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "        s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "        s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "        PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "        rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        try:\n",
        "            for i in range(images.size().getInfo()):\n",
        "\n",
        "                image = ee.Image(images.get(i))\n",
        "                date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "                # Compute PPI for the image\n",
        "                EVI2_image = computeEVI2(image)\n",
        "                EVI2_images.append(EVI2_image)\n",
        "\n",
        "            EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "            full_EVI2_collection = full_EVI2_collection.merge(median_EVI2_image)\n",
        "\n",
        "        except:\n",
        "          print('exception, block 2', date_range)\n",
        "          pass\n",
        "\n",
        "    #BLOCK3\n",
        "\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate(f'{year}-01-01', f'{year}-12-31').filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50))\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY').filterBounds(region).filterDate(f'{year}-01-01', f'{year}-12-31')\n",
        "    MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr,\n",
        "            secondary=s2Clouds,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "    def seasonal_amplitude(collection):\n",
        "        EVI_collection = collection.map(computeEVI2)\n",
        "        EVImax = EVI_collection.select('EVI2').reduce(ee.Reducer.max()).rename('EVImax')\n",
        "        EVImin = EVI_collection.select('EVI2').reduce(ee.Reducer.min()).rename('EVImin')\n",
        "\n",
        "\n",
        "        return EVImax.subtract(EVImin)\n",
        "\n",
        "    seas_amp = seasonal_amplitude(s2Sr)\n",
        "    seas_amp_median = seasonal_amplitude(full_EVI2_collection)\n",
        "\n",
        "    #BLOCK4\n",
        "\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "    MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "    EOS_median = ee.Image.constant(0)\n",
        "\n",
        "    full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "    for date_range in date_ranges[13:]: #phenology season\n",
        "        START_DATE = ee.Date(date_range['start_date'])\n",
        "        END_DATE = ee.Date(date_range['end_date'])\n",
        "        middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "        # Filter images by date range and region\n",
        "        criteria_a = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE))\n",
        "        criteria_b = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "        s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "        s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "        # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "        s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr_filtered,\n",
        "            secondary=s2Clouds_filtered,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "        s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "        s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "        PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "        rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        try:\n",
        "            for i in range(images.size().getInfo()):\n",
        "\n",
        "                image = ee.Image(images.get(i))\n",
        "                date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "                # Compute PPI for the image\n",
        "                EVI2_image = computeEVI2(image)\n",
        "                EVI2_images.append(EVI2_image)\n",
        "\n",
        "            EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "            # Define the threshold for the seasonal amplitude\n",
        "            threshold = seas_amp_median.multiply(0.15)\n",
        "\n",
        "            # Compute the median EVI2 image for the entire date range\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "\n",
        "            # Mask the median EVI2 image based on the thresholded seasonal amplitude\n",
        "            masked_median_EVI2_image = median_EVI2_image.updateMask(seas_amp_median.gt(threshold))\n",
        "\n",
        "            masked_median_EVI2_image = masked_median_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "            day_of_year = ee.Date(masked_median_EVI2_image.getInfo()['properties']['system:time_start']).difference(ee.Date(f'{year}-01-01'), 'days').round()\n",
        "\n",
        "            # Create a constant image representing the day of year\n",
        "            constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "            # Update the result image to store the start-of-season day for each pixel\n",
        "            EOS_median = EOS_median.where((masked_median_EVI2_image.select('EVI2').gt(threshold)), constant_day)\n",
        "\n",
        "            negative_condition = EOS_median.lte(0)\n",
        "\n",
        "            # Get the maximum EOS value\n",
        "            max_EOS_value = EOS_median.reduceRegion(\n",
        "                reducer=ee.Reducer.max(),\n",
        "                geometry=region,\n",
        "                scale=10\n",
        "            ).get('constant')\n",
        "\n",
        "            max_EOS_constant = ee.Image.constant(max_EOS_value)\n",
        "\n",
        "            # Set EOS_median to the maximum EOS value where it is negative\n",
        "            EM = EOS_median.where(negative_condition, max_EOS_constant)\n",
        "\n",
        "        except:\n",
        "          print('exception, block 4', date_range)\n",
        "          pass\n",
        "    Seasamp_yearly_list.append([year, seas_amp_median])\n",
        "    EOS_yearly_list.append([year,EM])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBWEG4kS_c49"
      },
      "source": [
        "## Seasonal Productivity 2019-2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 2"
      ],
      "metadata": {
        "id": "wR38rJSbhXCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7HWd1es_c9Z"
      },
      "outputs": [],
      "source": [
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "import traceback\n",
        "import sys\n",
        "\n",
        "# BLOCK 1\n",
        "\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "def map_SOS_EOS(image):\n",
        "    SOS, EOS = find_SOS_EOS(image, threshold=0.2)\n",
        "    return image.addBands(SOS.rename('SOS')).addBands(EOS.rename('EOS'))\n",
        "\n",
        "# DVImax_yearly = compute_yearly_DVImax(s2Sr)\n",
        "\n",
        "# Create a map centered at the region of interest\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "# BLOCK 2\n",
        "\n",
        "Season_len_yearly_list = []\n",
        "TP_yearly_list = []\n",
        "threshold1 = 0.2\n",
        "threshold2 = 0.2\n",
        "\n",
        "for year in [2019, 2020, 2021, 2022, 2023]:\n",
        "\n",
        "    date_ranges = get_date_ranges(year)\n",
        "\n",
        "    SOS_median = ee.Image.constant(0)\n",
        "    EOS_median = ee.Image.constant(0)\n",
        "\n",
        "    full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "    for date_range in date_ranges:  # phenology season\n",
        "        START_DATE = ee.Date(date_range['start_date'])\n",
        "        END_DATE = ee.Date(date_range['end_date'])\n",
        "        middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "        # Filter images by date range and region\n",
        "        criteria_a = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE))\n",
        "        criteria_b = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "        s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "        s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "        # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "        s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr_filtered,\n",
        "            secondary=s2Clouds_filtered,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "        s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "        s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "        PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "        rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        try:\n",
        "            for i in range(images.size().getInfo()):\n",
        "\n",
        "                image = ee.Image(images.get(i))\n",
        "                date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "                # Compute PPI for the image\n",
        "                EVI2_image = computeEVI2(image)\n",
        "                EVI2_images.append(EVI2_image)\n",
        "\n",
        "            EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "            full_EVI2_collection = full_EVI2_collection.merge(median_EVI2_image)\n",
        "\n",
        "        except Exception as e:\n",
        "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
        "            traceback.print_exception(exc_type, exc_value, exc_traceback)\n",
        "            print('Exception in block 2, date range:', date_range)\n",
        "            pass\n",
        "\n",
        "    # BLOCK 3\n",
        "\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate(f'{year}-01-01', f'{year}-12-31').filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 50))\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY').filterBounds(region).filterDate(f'{year}-01-01', f'{year}-12-31')\n",
        "    MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr,\n",
        "        secondary=s2Clouds,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "    def seasonal_amplitude(collection):\n",
        "        EVI_collection = collection.map(computeEVI2)\n",
        "        EVImax = EVI_collection.select('EVI2').reduce(ee.Reducer.max()).rename('EVImax')\n",
        "        EVImin = EVI_collection.select('EVI2').reduce(ee.Reducer.min()).rename('EVImin')\n",
        "\n",
        "        return EVImax.subtract(EVImin)\n",
        "\n",
        "    seas_amp = seasonal_amplitude(s2Sr)\n",
        "    seas_amp_median = seasonal_amplitude(full_EVI2_collection)\n",
        "\n",
        "    # BLOCK 4\n",
        "\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate('2018-01-01', '2023-12-31')\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "    MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "    SOS_median = ee.Image.constant(0)\n",
        "    EOS_median = ee.Image.constant(0)\n",
        "\n",
        "    full_EVI2_collection = ee.ImageCollection([])\n",
        "\n",
        "    for date_range in date_ranges[13:]:  # phenology season\n",
        "        START_DATE = ee.Date(date_range['start_date'])\n",
        "        END_DATE = ee.Date(date_range['end_date'])\n",
        "        middle_date = START_DATE.advance((END_DATE.difference(START_DATE, 'days')).divide(2), 'days')\n",
        "\n",
        "        # Filter images by date range and region\n",
        "        criteria_a = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE))\n",
        "        criteria_b = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "\n",
        "        s2Sr_filtered = s2Sr.filter(criteria_b)\n",
        "        s2Clouds_filtered = s2Clouds.filter(criteria_a)\n",
        "\n",
        "        # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "        s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "            primary=s2Sr_filtered,\n",
        "            secondary=s2Clouds_filtered,\n",
        "            condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "        )\n",
        "        s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "        s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "        PPIvis = {'min': -2, 'max': 2, 'palette': ['cyan', 'green', 'yellow', 'orange', 'red'], 'bands': ['PPI']}\n",
        "        rgbVis = {'min': 0, 'max': 2500, 'bands': ['B4', 'B3', 'B2']}\n",
        "\n",
        "        images = s2CloudMasked.toList(s2CloudMaskedWithNDSI.size())\n",
        "\n",
        "        EVI2_images = []\n",
        "\n",
        "        try:\n",
        "            for i in range(images.size().getInfo()):\n",
        "\n",
        "                image = ee.Image(images.get(i))\n",
        "                date = image.date().format('YYYY-MM-dd').getInfo()\n",
        "                # Compute PPI for the image\n",
        "                EVI2_image = computeEVI2(image)\n",
        "                EVI2_images.append(EVI2_image)\n",
        "\n",
        "            EVI2_collection = ee.ImageCollection(EVI2_images)\n",
        "\n",
        "            # Define the threshold for the seasonal amplitude\n",
        "            threshold_eos = seas_amp_median.multiply(0.15)\n",
        "\n",
        "            # Compute the median EVI2 image for the entire date range\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "            print('1', EVI2_collection.size().getInfo())\n",
        "\n",
        "            # Mask the median EVI2 image based on the thresholded seasonal amplitude\n",
        "            masked_median_EVI2_image = median_EVI2_image.updateMask(seas_amp_median.gt(threshold_eos))\n",
        "\n",
        "            masked_median_EVI2_image = masked_median_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "            day_of_year = ee.Date(masked_median_EVI2_image.getInfo()['properties']['system:time_start']).difference(ee.Date(f'{year}-01-01'), 'days').round()\n",
        "\n",
        "            # Create a constant image representing the day of year\n",
        "            constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "            # Update the result image to store the start-of-season day for each pixel\n",
        "            EOS_median = EOS_median.where((masked_median_EVI2_image.select('EVI2').gt(threshold_eos)), constant_day)\n",
        "\n",
        "            negative_condition = EOS_median.lte(0)\n",
        "\n",
        "            # Get the maximum EOS value\n",
        "            max_EOS_value = EOS_median.reduceRegion(\n",
        "                reducer=ee.Reducer.max(),\n",
        "                geometry=region,\n",
        "                scale=10\n",
        "            ).get('constant')\n",
        "\n",
        "            max_EOS_constant = ee.Image.constant(max_EOS_value)\n",
        "\n",
        "            # Set EOS_median to the maximum EOS value where it is negative\n",
        "            EM = EOS_median.where(negative_condition, max_EOS_constant)\n",
        "\n",
        "            threshold_sos = seas_amp_median.multiply(0.25)\n",
        "\n",
        "            # Compute the median EVI2 image for the entire date range\n",
        "            median_EVI2_image = EVI2_collection.median()\n",
        "            #print('2', EVI2_collection.size().getInfo())\n",
        "\n",
        "            # Mask the median EVI2 image based on the thresholded seasonal amplitude\n",
        "            masked_median_EVI2_image = median_EVI2_image.updateMask(seas_amp_median.gt(threshold_sos))\n",
        "\n",
        "            masked_median_EVI2_image_SOS = masked_median_EVI2_image.set('system:time_start', middle_date.millis())\n",
        "            #print(type(masked_median_EVI2_image_SOS))\n",
        "            day_of_year = ee.Date(masked_median_EVI2_image_SOS.getInfo()['properties']['system:time_start']).difference(ee.Date(f'{year}-01-01'), 'days').round()\n",
        "\n",
        "            # Create a constant image representing the day of year\n",
        "            constant_day = ee.Image.constant(day_of_year)\n",
        "\n",
        "            # Update the result image to store the start-of-season day for each pixel\n",
        "            SOS_median = SOS_median.where(SOS_median.eq(0).And(masked_median_EVI2_image_SOS.select('EVI2').gt(threshold_sos)), constant_day)\n",
        "\n",
        "            Season_len = EM.subtract(SOS_median)\n",
        "\n",
        "        except Exception as e:\n",
        "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
        "            traceback.print_exception(exc_type, exc_value, exc_traceback)\n",
        "            #print('Exception in block 4, date range:', date_range)\n",
        "            pass\n",
        "\n",
        "    Season_len_yearly_list.append(Season_len)\n",
        "'''\n",
        "    # Get the median SOS date as a constant value\n",
        "    median_sos = SOS_median.reduceRegion(ee.Reducer.median(), region, 10).get('constant')\n",
        "\n",
        "    # Get the median EOS date as a constant value\n",
        "    median_eos = EOS_median.reduceRegion(ee.Reducer.median(), region, 10).get('constant')\n",
        "\n",
        "    # Convert the median SOS and EOS dates into actual date objects\n",
        "    median_sos_date = ee.Date.fromYMD(year, 1, 1).advance(median_sos, 'day')\n",
        "    median_eos_date = ee.Date.fromYMD(year, 1, 1).advance(median_eos, 'day')\n",
        "\n",
        "    filtered_images = EVI2_collection.filterDate(median_sos_date, median_eos_date)\n",
        "\n",
        "    # Define a function to replace masked values with the mean of neighboring values\n",
        "    def fillMask(image):\n",
        "        # Replace masked values with the mean of neighboring values\n",
        "        filled_image = image.unmask().focal_mean(radius=1, kernelType='circle', units='pixels')\n",
        "        return filled_image\n",
        "\n",
        "    # Map the fillMask function over the filtered images\n",
        "    filtered_images_filled = filtered_images.map(fillMask)\n",
        "\n",
        "    # Compute the sum of EVI2 values for each image\n",
        "    sum_images = filtered_images_filled.sum()\n",
        "\n",
        "    TP_yearly_list.append(sum_images)\n",
        "\n",
        "# Print the results\n",
        "for year, season_len, tp in zip([2019, 2020, 2021, 2022, 2023], Season_len_yearly_list, TP_yearly_list):\n",
        "    print(f\"Year: {year}\")\n",
        "    print(f\"Season Length: {season_len.getInfo()}\")\n",
        "    print(f\"Total Productivity: {tp.getInfo()}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 2"
      ],
      "metadata": {
        "id": "wAwQvsWihZ8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeEVI2(image):\n",
        "    \"\"\"Compute the EVI2 index for a given image.\"\"\"\n",
        "    NIR = image.select('B8')  # Assuming NIR band is labeled as B8\n",
        "    red = image.select('B4')  # Assuming red band is labeled as B4\n",
        "    DVI = NIR.subtract(red).rename('DVI')\n",
        "    EVI2 = ee.Image(2.5).multiply(DVI) \\\n",
        "        .divide(NIR.add(ee.Image(2.4).multiply(red)).add(ee.Image(1))).rename('EVI2')\n",
        "    return image.addBands(EVI2)\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "# Function to compute the mean EVI2 value from April 1 to December 1\n",
        "def compute_mean_EVI2(year, threshold):\n",
        "    start_date = f'{year}-04-01'\n",
        "    end_date = f'{year}-12-01'\n",
        "\n",
        "    # Load Sentinel-2 image collection for the given period\n",
        "    s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(region).filterDate(start_date, end_date).filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", 80))\n",
        "    s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY').filterBounds(region).filterDate(start_date, end_date)\n",
        "\n",
        "    # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr,\n",
        "        secondary=s2Clouds,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "    EVI2_images = s2CloudMasked.map(lambda img: computeEVI2(img).select('EVI2').updateMask(computeEVI2(img).select('EVI2').gte(threshold)))\n",
        "\n",
        "    mean_EVI2 = EVI2_images.mean().clip(region).rename('mean_EVI2')\n",
        "\n",
        "    return mean_EVI2\n",
        "\n",
        "# List to store results\n",
        "TP_yearly_list = []\n",
        "\n",
        "# Years to process\n",
        "years = [2019, 2020, 2021, 2022, 2023]\n",
        "threshold = 0.2\n",
        "\n",
        "# Process each year\n",
        "for k, year in enumerate(years):\n",
        "    mean_EVI2 = compute_mean_EVI2(year, threshold)\n",
        "    season_length = season_length_list[k][1]\n",
        "    total_productivity = mean_EVI2.multiply(season_length).rename('total_productivity')\n",
        "    TP_yearly_list.append([total_productivity, year])\n",
        "    print(f\"Computed total productivity for year {year}\")"
      ],
      "metadata": {
        "id": "3BWHZEBBhaBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Season Len"
      ],
      "metadata": {
        "id": "RrxGuscU3gY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Initialize the Earth Engine module\n",
        "ee.Initialize()\n",
        "\n",
        "# Function to calculate the season length\n",
        "def calculate_season_length(sos_eos_tuple):\n",
        "    year, sos_image = sos_eos_tuple[0]\n",
        "    eos_image = sos_eos_tuple[1][1]  # Assuming corresponding images match by index\n",
        "    season_length = eos_image.subtract(sos_image)\n",
        "    # Replace negative values with 0 using the max function\n",
        "    season_length = season_length.max(0)\n",
        "    return (season_length, year)\n",
        "\n",
        "# Pair up corresponding SOS and EOS images by year\n",
        "paired_images = list(zip(SOS_yearly_list, EOS_yearly_list))\n",
        "\n",
        "# Calculate the season length for each pair\n",
        "season_length_list = [calculate_season_length(pair) for pair in paired_images]\n",
        "\n",
        "# Print or visualize the results\n",
        "for season_length, year in season_length_list:\n",
        "    print(f\"Year: {year}\")\n",
        "    season_length_info = season_length.getInfo()\n",
        "    min_value = season_length_info['bands'][0]['data_type']['min']\n",
        "    max_value = season_length_info['bands'][0]['data_type']['max']\n",
        "    print(f\"Season Length Image Min Value: {min_value}, Max Value: {max_value}\")"
      ],
      "metadata": {
        "id": "uxULCdX-3gdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export images to Drive"
      ],
      "metadata": {
        "id": "YwLfb8vn83UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export SOS images\n",
        "for year, image in SOS_yearly_list:\n",
        "    print(type(image))\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, SOS',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing SOS for year {year}')\n",
        "    time.sleep(100)\n",
        "\n",
        "\n",
        "# Export EOS images\n",
        "for year, image in EOS_yearly_list:\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, EOS',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing EOS for year {year}')\n",
        "    time.sleep(100)\n",
        "\n",
        "# Export Seasamp images\n",
        "for year, image in Seasamp_yearly_list:\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, Seasamp',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing Seasamp for year {year}')\n",
        "    time.sleep(100)\n",
        "\n",
        "# Export Greenup images\n",
        "for year, image in greenup_yearly_list:\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, Greenup',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing greenup for year {year}')\n",
        "    time.sleep(200)\n",
        "\n",
        "# Export Greendown images\n",
        "for year, image in greendown_yearly_list:\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, Greendown',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing Greendown for year {year}')\n",
        "    time.sleep(100)\n",
        "\n",
        "# Export TP images\n",
        "for image, year in TP_yearly_list:\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, TP',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing TP for year {year}')\n",
        "    time.sleep(100)\n",
        "\n",
        "# Export Season Length images\n",
        "for image, year in season_length_list:\n",
        "    export_params = {\n",
        "      'image': image,\n",
        "      'description': f'{year}, season_length',  # Specify the file name\n",
        "      'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "      'scale': 10,  # Adjust the scale as needed\n",
        "      'region': region,  # Define the region of interest\n",
        "      'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "    }\n",
        "    task = ee.batch.Export.image.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f'exporing season_length for year {year}')\n",
        "    time.sleep(100)\n"
      ],
      "metadata": {
        "id": "YA6lCK2JIJgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "p6V1TyqsVr7o",
        "IfeC-SyPakkB",
        "IY9nOeUwuwXJ",
        "mxR0IV6ly3UI",
        "Rkx_g1IOvFZH",
        "VXmOM4WHFfJF",
        "bLSnL0nd_HPg",
        "giLCnLSQHptM",
        "-UyuyaFC_Rko",
        "SQqIsNgbALk-",
        "EmoO7kL4vFTf",
        "SOoA0dKVZ4j1",
        "wR38rJSbhXCA"
      ],
      "mount_file_id": "1btAgPZZJszN1KQsFen6OCXsN5X8aBXgW",
      "authorship_tag": "ABX9TyOTDCRJsSg/5JGvSJ/n+/Na",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}