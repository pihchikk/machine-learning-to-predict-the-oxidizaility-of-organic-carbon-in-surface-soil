{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTXx9j3GYllwIbvr8cbgdT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pihchikk/machine-learning-to-predict-the-oxidizaility-of-organic-carbon-in-surface-soil/blob/main/notebooks/data%20preprocessing/Tambov_Snowcover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auth"
      ],
      "metadata": {
        "id": "gyvCTdNe-dzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-shrgnn')"
      ],
      "metadata": {
        "id": "VR5WfMpS-c-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROI"
      ],
      "metadata": {
        "id": "XunKfFs58jyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyproj import Proj, transform\n",
        "\n",
        "# Define the EPSG code for EPSG:32637 (UTM Zone 37N) and WGS84\n",
        "epsg_32637 = Proj(init='epsg:32637')\n",
        "wgs84 = Proj(init='epsg:4326')\n",
        "\n",
        "# Coordinates in EPSG:32637\n",
        "x1, y1 = 647700, 5766250\n",
        "x2, y2 = 651100, 5769600\n",
        "\n",
        "# Convert EPSG:32637 coordinates to WGS84\n",
        "lon1, lat1 = transform(epsg_32637, wgs84, x1, y1)\n",
        "lon2, lat2 = transform(epsg_32637, wgs84, x2, y2)\n",
        "\n",
        "# Print the result\n",
        "print(\"Longitude:\", lon1, lon2)\n",
        "print(\"Latitude:\", lat1, lat2)\n",
        "\n",
        "region = ee.Geometry.Polygon(\n",
        "  [[[lon1, lat2],\n",
        "    [lon1, lat1],\n",
        "    [lon2, lat1],\n",
        "    [lon2, lat2]]], None, False)\n"
      ],
      "metadata": {
        "id": "VghMGE6E8w7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pixelwise snow/nosnow comparison for sentinel2 GEE collections"
      ],
      "metadata": {
        "id": "_xKhnOOH8neh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count pixels"
      ],
      "metadata": {
        "id": "7iLMxM_ENkan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSdFvmRV8WHo"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import folium\n",
        "\n",
        "region = region\n",
        "\n",
        "# Load Sentinel-2 surface reflectance imagery\n",
        "s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "MAX_CLOUD_PROBABILITY = 65\n",
        "\n",
        "# Function to mask clouds\n",
        "def maskClouds(img):\n",
        "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
        "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
        "    return img.updateMask(isNotCloud)\n",
        "\n",
        "# Function to mask edges\n",
        "def maskEdges(s2_img):\n",
        "    return s2_img.updateMask(\n",
        "        s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
        "\n",
        "# Function to compute NDSI\n",
        "def computeNDSI(img):\n",
        "    ndsi = img.normalizedDifference(['B3', 'B11']).rename('NDSI')\n",
        "    ndsi2 = img.normalizedDifference(['B3', 'B12']).rename('NDSI2')\n",
        "    return img.addBands(ndsi).addBands(ndsi2)\n",
        "\n",
        "def snow_classifier(img):\n",
        "    NDSI = img.select('NDSI')\n",
        "    B03 = img.select('B3')\n",
        "    NDVI = img.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "\n",
        "    # Thresholds\n",
        "    NDSI_threshold = 0.4\n",
        "    brightness_threshold = 0.3\n",
        "\n",
        "    # Conditions for snow classification\n",
        "    snow_mask_1 = NDSI.gt(NDSI_threshold)\n",
        "    snow_mask_2 = NDSI.gt(0.42).And(NDVI.subtract(0.1).abs().lte(0.025))\n",
        "    snow_mask_3 = NDSI.gt(0.3).And(B03.gt(brightness_threshold))\n",
        "\n",
        "    # Final snow mask\n",
        "    snow_mask = snow_mask_1.Or(snow_mask_2).Or(snow_mask_3)\n",
        "\n",
        "    return snow_mask\n",
        "\n",
        "\n",
        "map = folium.Map(location=[52.03, 41.16], zoom_start=10)\n",
        "\n",
        "\n",
        "years = (2019,2020,2021,2022,2023,2024)\n",
        "\n",
        "snow_counts_full = ee.Image.constant(0)\n",
        "no_snow_counts_full = ee.Image.constant(0)\n",
        "\n",
        "snow = []\n",
        "nosnow = []\n",
        "\n",
        "for j in years:\n",
        "    # Create a map centered at the region of interest\n",
        "    # Initialize empty images to store counts for each class\n",
        "    snow_counts_img = ee.Image.constant(0)\n",
        "    no_snow_counts_img = ee.Image.constant(0)\n",
        "    cloud_counts_img = ee.Image.constant(0)\n",
        "\n",
        "\n",
        "    START_DATE = ee.Date(f'{j-1}-10-20')\n",
        "    END_DATE = ee.Date(f'{j}-04-20')\n",
        "\n",
        "    criteria = ee.Filter.And(\n",
        "            ee.Filter.bounds(region),\n",
        "            ee.Filter.date(START_DATE, END_DATE),\n",
        "            #ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE',90)\n",
        "        )\n",
        "\n",
        "    s2Sr_filtered = s2Sr.filter(criteria)\n",
        "    s2Clouds_filtered = s2Clouds.filter(criteria)\n",
        "\n",
        "    # Join S2 SR with cloud probability dataset to add cloud mask\n",
        "    s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
        "        primary=s2Sr_filtered,\n",
        "        secondary=s2Clouds_filtered,\n",
        "        condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
        "    )\n",
        "\n",
        "    # Apply cloud mask and calculate median\n",
        "    s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskEdges).map(maskClouds)\n",
        "\n",
        "    # Compute NDSI\n",
        "    s2CloudMaskedWithNDSI = s2CloudMasked.map(computeNDSI)\n",
        "\n",
        "    images = s2CloudMaskedWithNDSI.toList(s2CloudMaskedWithNDSI.size())\n",
        "    img_orig = s2SrWithCloudMask.toList(s2SrWithCloudMask.size())\n",
        "\n",
        "    # Loop through images\n",
        "    l = len(images.getInfo()) #for calculation of the last collection member\n",
        "    for i in range(images.size().getInfo()):\n",
        "        image = ee.Image(images.get(i))\n",
        "\n",
        "        # Create masks\n",
        "        snow_mask = image.select('NDSI').gt(0.44).And(image.select('B3').gt(0.4))\n",
        "        no_snow_mask = image.select('NDSI').lte(0.44).Or(image.select('B3').lte(0.4))\n",
        "        na_mask = ee.Image(image.get('cloud_mask')).select('probability').gt(MAX_CLOUD_PROBABILITY)\n",
        "\n",
        "\n",
        "\n",
        "        # Increment counts for each class\n",
        "        #snow_counts_full = snow_counts_img.where(snow_mask, snow_counts_full.add(1))\n",
        "        #no_snow_counts_full = no_snow_counts_img.where(no_snow_mask, no_snow_counts_full.add(1))\n",
        "        snow_counts_img = snow_counts_img.where(snow_mask, snow_counts_img.add(1))\n",
        "        no_snow_counts_img = no_snow_counts_img.where(no_snow_mask, no_snow_counts_img.add(1))\n",
        "        cloud_counts_img = cloud_counts_img.where(na_mask, cloud_counts_img.add(1))\n",
        "\n",
        "        #snow_mask = snow_classifier(image)\n",
        "        #no_snow_mask = snow_mask.Not()\n",
        "\n",
        "\n",
        "        if int(i)>=l-1:\n",
        "            print(l)\n",
        "            snow.append(snow_counts_img)\n",
        "            nosnow.append(no_snow_counts_img)\n",
        "\n",
        "        # Clip images to the ROI\n",
        "        #snow_counts_full = snow_counts_full.clip(region)\n",
        "        #no_snow_counts_full = no_snow_counts_full.clip(region)\n",
        "        snow_counts_img = snow_counts_img.clip(region)\n",
        "        no_snow_counts_img = no_snow_counts_img.clip(region)\n",
        "        cloud_counts_img = cloud_counts_img.clip(region)\n",
        "\n",
        "    SnowyFrac = snow_counts_img.divide(no_snow_counts_img)\n",
        "    mapid6 = SnowyFrac.getMapId({'min': 0, 'max': 2, 'palette': ['red', 'orange', 'yellow', 'green', 'cyan']})  # Assuming cloud_counts_img is your Earth Engine Image\n",
        "    folium.TileLayer(\n",
        "        tiles=mapid6['tile_fetcher'].url_format,\n",
        "        attr='Google Earth Engine',\n",
        "        overlay=True,\n",
        "        opacity=0.5,\n",
        "        name=f'SnowyFrac {j}'\n",
        "    ).add_to(map)  # Assuming Map is your Folium map instance\n",
        "'''\n",
        "SnowyFracFull = snow_counts_full.divide(no_snow_counts_full)\n",
        "\n",
        "mapid8 = SnowyFracFull.getMapId({'min': 0, 'max': 2, 'palette': ['red', 'orange', 'yellow', 'green', 'cyan']})  # Assuming cloud_counts_img is your Earth Engine Image\n",
        "folium.TileLayer(\n",
        "    tiles=mapid8['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    opacity=0.5,\n",
        "    name=f'median Snowyfrac image'\n",
        ").add_to(map)  # Assuming Map is your Folium map instance\n",
        "'''\n",
        "\n",
        "# Add the ROI polygon to the map\n",
        "roi_geojson = region.getInfo()\n",
        "folium.GeoJson(roi_geojson, name='ROI').add_to(map)\n",
        "\n",
        "# Display the map\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Image"
      ],
      "metadata": {
        "id": "eG1hufvHb1Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_params = {\n",
        "    'image': SnowyFrac,\n",
        "    'description': 'median_snowy_frac_image_default',  # Specify the file name\n",
        "    'folder': 'GEE_images',  # Specify the folder in your Google Drive\n",
        "    'scale': 10,  # Adjust the scale as needed\n",
        "    'region': region,  # Define the region of interest\n",
        "    'maxPixels': 1e13  # Specify the maximum number of pixels\n",
        "}\n",
        "\n",
        "# Start the export task\n",
        "task = ee.batch.Export.image.toDrive(**export_params)\n",
        "task.start()\n",
        "\n",
        "# Print the task status\n",
        "print('Exporting median SnowyFrac image to Google Drive...')\n"
      ],
      "metadata": {
        "id": "WVW2q1MDhMla"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}